{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class OpenEyesClassificator(nn.Module):\n",
    "#     def __init__(self, dropout_rate=0.6):\n",
    "#         super(OpenEyesClassificator, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(32)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(64)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.fc1 = nn.Linear(64 * 28 * 28, 128)\n",
    "#         self.bn3 = nn.BatchNorm1d(128)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(128, 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.relu1(self.bn1(self.conv1(x))))\n",
    "#         x = self.dropout1(x)\n",
    "        \n",
    "#         x = self.pool(self.relu2(self.bn2(self.conv2(x))))\n",
    "#         x = self.dropout2(x)\n",
    "        \n",
    "#         print(x.shape)\n",
    "#         # x = x.view(-1, 64 * 28 * 28)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "#         x = self.relu3(self.bn3(self.fc1(x)))\n",
    "#         x = self.dropout3(x)\n",
    "        \n",
    "#         x = self.sigmoid(self.fc2(x))\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class OpenEyesClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OpenEyesClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding='same')\n",
    "        self.leaky_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
    "        self.leaky_relu2 = nn.LeakyReLU(0.1)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
    "        self.leaky_relu3 = nn.LeakyReLU(0.1)\n",
    "        self.max_pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1152, 128) \n",
    "        self.leaky_relu4 = nn.LeakyReLU(0.1)\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        # self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu1(self.conv1(x))\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.leaky_relu2(self.conv2(x))\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.leaky_relu3(self.conv3(x))\n",
    "        x = self.max_pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.leaky_relu4(self.fc1(x))\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        # x = self.sigmoid(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        # return self.logsoftmax(x)\n",
    "        return self.sigmoid(x)\n",
    "        # return self.softmax(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "def compute_eer(labels, scores):\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    eer_index = np.argmin(np.abs(fnr - fpr))\n",
    "    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n",
    "    thresh = thresholds[eer_index]\n",
    "    return eer, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eer_(labels, scores):\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "    frr = 1 - tpr\n",
    "    abs_diffs = np.abs(fpr - frr)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = (fpr[min_index]+ frr[min_index])/2\n",
    "    \n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, labels):\n",
    "    correct = (preds == labels).sum().item()\n",
    "    total = preds.shape[0]\n",
    "\n",
    "    return correct/total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def evaluate_model(model, criterion, val_loader, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    val_labels_list = []\n",
    "    val_preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for it in val_loader:\n",
    "            inputs, labels = it['image'].to(device), it['label'].to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs.permute(1,0), labels.unsqueeze(0))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_labels_list += labels.unsqueeze(0).cpu().detach().numpy().tolist()\n",
    "            val_preds_list += outputs.permute(1,0).cpu().detach().numpy().tolist()\n",
    "\n",
    "        val_eer = compute_eer_(val_labels_list[0], val_preds_list[0])\n",
    "        preds = (torch.tensor(val_labels_list[0]) >= 0.5).float()\n",
    "\n",
    "        val_acc = compute_accuracy(preds, torch.tensor(val_labels_list[0]))\n",
    "\n",
    "    return val_loss, val_acc, val_eer\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, ckpts_path, num_epochs=1, scheduler=None, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    min_eer = np.inf\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training phase ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        train_labels_list = []\n",
    "        train_preds_list = []\n",
    "        \n",
    "        for it in train_loader:\n",
    "            inputs, labels = it['image'].to(device), it['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs.permute(1,0).shape, labels.unsqueeze(0).shape)\n",
    "            loss = criterion(outputs.permute(1,0), labels.unsqueeze(0))\n",
    "            # eer_train = compute_eer_(labels.unsqueeze(0).cpu().detach().numpy(), outputs.permute(1,0).cpu().detach().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "\n",
    "            train_labels_list += labels.unsqueeze(0).cpu().detach().numpy().tolist()\n",
    "            train_preds_list += outputs.permute(1,0).cpu().detach().numpy().tolist()\n",
    "\n",
    "\n",
    "        train_eer = compute_eer_(train_labels_list[0], train_preds_list[0])\n",
    "        preds = (torch.tensor(train_preds_list[0]) >= 0.5).float()\n",
    "\n",
    "        train_acc = compute_accuracy(preds, torch.tensor(train_labels_list[0]))\n",
    "\n",
    "\n",
    "        print(train_acc, train_eer)\n",
    "\n",
    "        val_loss, val_acc, val_eer = evaluate_model(model, criterion, val_loader, device=device)\n",
    "\n",
    "        wandb.log({\"epoch\": epoch, \"loss\": val_loss, \"train_accuracy\": train_acc, \"train_eer\": train_eer, \\\n",
    "                   \"val_loss\": val_loss, \"val_accuracy\": val_acc, \"val_eer\": val_eer})\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if val_eer < min_eer or val_eer < 0.01:\n",
    "            min_eer = val_eer\n",
    "            torch.save(model.state_dict(), ckpts_path)\n",
    "            print(f\"Saved model with validation accuracy = {val_acc:.4f} and eer = {val_eer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_dir = '/home/sadevans/space/CloseEyesClassifier/data/clustered_auto_tcne_CHECKED/open'\n",
    "close_dir = '/home/sadevans/space/CloseEyesClassifier/data/clustered_auto_tcne_CHECKED/close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_image_paths_and_labels(open_dir, close_dir):\n",
    "    open_images = [os.path.join(open_dir, img) for img in os.listdir(open_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
    "    close_images = [os.path.join(close_dir, img) for img in os.listdir(close_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
    "    images = open_images + close_images\n",
    "    labels = [1] * len(open_images) + [0] * len(close_images)\n",
    "    return images, labels\n",
    "\n",
    "# Перемешать пути изображений и метки классов\n",
    "def shuffle_data(images, labels):\n",
    "    combined = list(zip(images, labels))\n",
    "    random.shuffle(combined)\n",
    "    images[:], labels[:] = zip(*combined)\n",
    "    return images, labels\n",
    "\n",
    "# Разделить данные на обучающую, валидационную и тестовую выборки\n",
    "def split_data(images, labels):\n",
    "    train_images, temp_images, train_labels, temp_labels = train_test_split(images, labels, test_size=0.4, stratify=labels, random_state=42)\n",
    "    val_images, test_images, val_labels, test_labels = train_test_split(temp_images, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n",
    "    return train_images, val_images, test_images, train_labels, val_labels, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2400 images\n",
      "Validation: 800 images\n",
      "Test: 800 images\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# Загрузить данные\n",
    "images, labels = load_image_paths_and_labels(open_dir, close_dir)\n",
    "\n",
    "# Перемешать данные\n",
    "images, labels = shuffle_data(images, labels)\n",
    "\n",
    "# Разделить данные\n",
    "train_images, val_images, test_images, train_labels, val_labels, test_labels = split_data(images, labels)\n",
    "\n",
    "print(f\"Train: {len(train_images)} images\")\n",
    "print(f\"Validation: {len(val_images)} images\")\n",
    "print(f\"Test: {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ImageTransform, EyeDataset\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# seed = 42\n",
    "\n",
    "train_dataset = EyeDataset(train_images, train_labels, transform=ImageTransform('train'))\n",
    "val_dataset = EyeDataset(val_images, val_labels, transform=ImageTransform('val'))\n",
    "test_dataset = EyeDataset(test_images, test_labels, transform=ImageTransform('test'))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.4893954396247864, 0.4759499430656433, 0.4773009419441223, 0.4791807532310486, 0.48713383078575134, 0.4869005084037781, 0.4673452377319336, 0.48795607686042786, 0.4844638705253601, 0.4944532513618469, 0.4771513044834137, 0.5044295191764832, 0.504009485244751, 0.4867953360080719, 0.4812712073326111, 0.4881991446018219, 0.4882332980632782, 0.4848036468029022, 0.4834272861480713, 0.47826460003852844, 0.4839402735233307, 0.4751614034175873, 0.48781877756118774, 0.4845618009567261, 0.48473361134529114, 0.4863566756248474, 0.44750821590423584, 0.4907439351081848, 0.47800448536872864, 0.4870065450668335, 0.47488510608673096, 0.49149301648139954]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "0.40625 0.3765182186234818\n",
      "[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[0.33174967765808105, 0.1989264041185379, 0.09188774228096008, 0.3854682445526123, 0.553437352180481, 0.6083850264549255, 0.3585776388645172, 0.35463184118270874, 0.3325105905532837, 0.12640617787837982, 0.5627367496490479, 0.48244449496269226, 0.4299934506416321, 0.3643054664134979, 0.5961963534355164, 0.40334972739219666, 0.44589412212371826, 0.272348016500473, 0.40761542320251465, 0.3736898601055145, 0.43644261360168457, 0.28981274366378784, 0.3461391031742096, 0.006476952228695154, 0.21261394023895264, 0.37049445509910583, 0.33698970079421997, 0.3567812144756317, 0.4059474766254425, 0.3943443298339844, 0.11422312259674072, 0.32595357298851013]\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "0.75 0.20833333333333331\n",
      "[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
      "[0.6937605142593384, 0.8369302749633789, 0.9165211319923401, 0.10218139737844467, 0.06358007341623306, 0.3134506344795227, 0.8661211133003235, 0.17809396982192993, 0.29590678215026855, 0.7487822771072388, 0.703373372554779, 0.020850397646427155, 0.8565446734428406, 0.4276587665081024, 0.9497135281562805, 0.23988594114780426, 0.19954301416873932, 0.013956202194094658, 0.6662201285362244, 0.6561607718467712, 0.05662770941853523, 0.7619263529777527, 0.5065041184425354, 0.22613373398780823, 0.0706021711230278, 0.12474113702774048, 0.5732383728027344, 0.018787547945976257, 0.793663501739502, 0.854628324508667, 0.857669472694397, 0.8404795527458191]\n",
      "tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "0.90625 0.126984126984127\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
      "[0.8199045062065125, 0.16890563070774078, 0.00696823513135314, 0.3844105899333954, 0.1818436086177826, 0.3099575638771057, 0.9756356477737427, 0.9406208395957947, 0.9630036354064941, 0.32667598128318787, 0.13916543126106262, 0.03490007296204567, 0.35542377829551697, 0.7779425382614136, 0.05797755345702171, 0.025842107832431793, 0.8690186738967896, 0.5184258222579956, 0.23226793110370636, 0.06701619178056717, 0.8830446600914001, 0.6881607174873352, 0.023325473070144653, 0.22995494306087494, 0.9901700615882874, 0.5255812406539917, 0.500205934047699, 0.6069810390472412, 0.9417162537574768, 0.602498471736908, 0.9330940842628479, 0.5691987872123718]\n",
      "tensor([1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "0.6875 0.18614718614718612\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.006989374291151762, 0.11310924589633942, 0.025457458570599556, 0.7038582563400269, 0.010607226751744747, 0.8623182773590088, 0.3527199625968933, 0.9783855080604553, 0.17358414828777313, 0.005938518326729536, 0.28200289607048035, 0.04583659768104553, 0.9248193502426147, 0.7081944346427917, 0.1334836781024933, 0.6987411379814148, 0.29800209403038025, 0.7952925562858582, 0.05812333524227142, 0.02991143800318241, 0.280710905790329, 0.12331393361091614, 0.20441372692584991, 0.9190158843994141, 0.9395353198051453, 0.8169547915458679, 0.057672884315252304, 0.7765129208564758, 0.04229488596320152, 0.042773839086294174, 0.11672025173902512, 0.013468015938997269]\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "0.96875 0.022727272727272728\n"
     ]
    }
   ],
   "source": [
    "model = OpenEyesClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
